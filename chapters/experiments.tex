\chapter{Experiments} \label{exp}

\section{Dataset}

Training a neural network requires convenient ground truth. Recently well-estimated normals suitable to use as ground truth were not available. For example, the widely used NUYv2 dataset contained geometrically estimated normals and thus was quite noisy. This problem was addressed by several researchers \cite{matterport, physically-based-rendering}. In our work, we use Matterport dataset \cite{matterport}, which contains rich information about indoor environments including multi-view reconstructed meshes and normals. This data has been used extensively since Matterport dataset had been published \cite{deep_surf, deep_depth_compl}; many usages proved that it is quite reliable to be used as ground truth for normal estimation tasks.

\section{Results}

We evaluated our algorithm on the Matterport dataset, comparing it with several depth-based and RGBD-based algorithms. For consistency, we used the same evaluation metrics as other researchers do \cite{deep_surf, deep_depth_compl}. They consist of:
\begin{itemize}
    \item mean angle distance in degrees between predicted and ground-truth normals;
    \item median angle distance between predicted and ground-truth normals;
    \item fraction of pixels where error is less than $11.25^{\circ}$;
    \item fraction of pixels where error is less than $22.5^{\circ}$;
    \item fraction of pixels where error is less than $30^{\circ}$;
    \item time to process one RGBD image from the Matterport dataset.
\end{itemize}

Results can be found in the table \ref{table:qual}. It is seen that our algorithm did not outperform state-of-the-art algorithm HFM \cite{deep_surf} while being quite close to it. We consider this a good result as soon as that approach uses both depth and color channels while we use only depth. Also, results show that our algorithm outperformed other depth-based methods as well as the open3d \cite{open3d} baseline.

Also, it worth mentioning that NN approaches remarkably outperform the end-to-end time of our algorithm. We believe that this comes from the fact that other methods' inference is made entirely on GPU, while we perform multiscale normal estimation on CPU, and only the fusion part is executed on GPU. Our further work plans include reimplementing the algorithm from section \ref{integ-im} to run on GPU, and by that achieving comparable results.

\begin{table}
\centering
\begin{tabular}{ | c | c | c | c | c | c | c | c | }
\hline
 & \multicolumn{2}{|c|}{Depth based} & \multicolumn{2}{|c|}{RGBD based} & \multicolumn{2}{|c|}{\textbf{MsNE (Ours)}} & \\
 \hline
 & Levin's \cite{colorization-using-optimization} & DC \cite{deep_depth_compl} & GFMM \cite{guided-depth-enhancement} & HFM \cite{deep_surf} & \textbf{FCN} & \textbf{UNet} & Open3d \cite{open3d} \\
 \hline
 Mean & 21.588  & 19.126 & 16.537 & \textbf{13.062} & 15.54 & \textbf{15.11} & 20.94 \\  
 \hline
 Median & 12.079  & 9.563 & 8.028 & \textbf{6.090} & 8.40 & \textbf{8.31} & 13.66 \\  
 \hline
 $11.25^{\circ}$ & 58.07  & 64.89 & 65.3 & \textbf{72.23} & 70.46 & \textbf{71.82} & 50.63\\
 \hline
 $22.5^{\circ}$ & 69.59 & 78.5 & 79.94 & \textbf{84.41} & 83.16 & \textbf{84.01} & 75.11 \\
 \hline
 $30^{\circ}$ & 75.0  & 79.22 & 84.16 & \textbf{88.31} & 86.67 & \textbf{87.4} & 81.43 \\
 \hline
  Time & 0.95s  & 0.21s &  0.19s & 0.085s & \multicolumn{2}{|c|}{1.5 + 0.015s} & 0.92s \\
  \hline
\end{tabular}
\caption{Comparison of normal estimation algorithms quality.}
\label{table:qual}
\end{table}
