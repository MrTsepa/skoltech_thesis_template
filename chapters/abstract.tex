In this work, a new approach is proposed to solve a task of surface normal prediction from RGBD data. This approach consists of estimating normals on different scales using known geometrical methods and then fusing them to get final convenient normals estimation. Fusing is done by a fully convolutional neural network trained on multiview reconstructed normals captured from indoor environments. Comparing this approach and existing ones shows that it reaches nearly state-of-the-art quality while relying only on depth data, not using color channels. A very efficient implementation of the algorithm is also proposed, making it outperform modern point cloud libraries.